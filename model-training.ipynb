{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4d7a8c",
   "metadata": {},
   "source": [
    "### Court Corners clicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# This list will store the clicked points\n",
    "points = []\n",
    "\n",
    "def select_points(event, x, y, flags, param):\n",
    "    \"\"\"\n",
    "    Mouse callback function to capture clicks.\n",
    "    \"\"\"\n",
    "    global points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points.append((x, y))\n",
    "        # Draw a circle on the clicked point for visual feedback\n",
    "        cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "        print(f\"Point {len(points)} captured: ({x}, {y})\")\n",
    "\n",
    "# --- Main Script ---\n",
    "VIDEO_PATH = \"VideoInput/video_input2.mp4\" # Make sure this path is correct\n",
    "WINDOW_NAME = \"Click to Select Points\"\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load the first frame of the video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 50)\n",
    "ret, image = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to load video.\")\n",
    "else:\n",
    "    image = cv2.resize(image, (960, 540)) # Use your standard resize\n",
    "    clone = image.copy() # Keep a clean copy of the image\n",
    "\n",
    "    # 2. Set up the window and mouse callback\n",
    "    cv2.namedWindow(WINDOW_NAME)\n",
    "    cv2.setMouseCallback(WINDOW_NAME, select_points)\n",
    "\n",
    "    # 3. Wait for the user to click 4 points\n",
    "    print(\"Please click on the 4 service box corners in this order:\")\n",
    "    print(\"1. Top-Left -> 2. Top-Right -> 3. Bottom-Left -> 4. Bottom-Right\")\n",
    "    print(\"Press 'r' to reset points. Press 'q' to quit when done.\")\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow(WINDOW_NAME, image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('r'): # Reset if you make a mistake\n",
    "            image = clone.copy()\n",
    "            points = []\n",
    "            print(\"Points reset.\")\n",
    "\n",
    "        elif key == ord('q') or len(points) == 4:\n",
    "            break\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "    # 4. Print the final result in the required format\n",
    "    if len(points) == 4:\n",
    "        print(\"\\nSUCCESS! Copy this into your main script:\")\n",
    "        src_points = np.float32(points)\n",
    "        print(f\"src_points = np.float32({src_points.tolist()})\")\n",
    "    else:\n",
    "        print(\"\\nDid not select 4 points. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349b74c",
   "metadata": {},
   "source": [
    "### Simple line detector\n",
    "focuses on central region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18beac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Court Detection \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load video\n",
    "video_path = \"VideoInput/video_input2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Reset lines a each frame\n",
    "    court_lines = []\n",
    "    \n",
    "    # Resize for speed\n",
    "    frame = cv2.resize(frame, (960, 540))\n",
    "    \n",
    "    #Preprocess the frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "\n",
    "    # Line detection using Hough Transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=40, maxLineGap=25)\n",
    "    \n",
    "    #draw limit lines\n",
    "    cv2.line(frame, (170, 130), (170, 445), (255, 0, 0), 1)\n",
    "    cv2.line(frame, (170, 445), (790, 445), (255, 0, 0), 1)\n",
    "    \n",
    "    cv2.line(frame, (170, 130), (790, 130), (255, 0, 0), 1)\n",
    "    cv2.line(frame, (790, 130), (790, 445), (255, 0, 0), 1)\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            \n",
    "            # Compute line angle in degrees\n",
    "            if max(y1, y2) > 445 or min(y1, y2) < 130:\n",
    "                continue\n",
    "            if max(x1, x2) > 790 or min(x1, x2) < 170:\n",
    "                continue\n",
    "            \n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "            if -15 < angle < 15:\n",
    "                cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                court_lines.append(lines)\n",
    "            elif abs(angle) > 45 and abs(angle) < 85:\n",
    "                cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                court_lines.append(line)\n",
    "            \n",
    "            \"\"\" # Filter: keep near-horizontal (0° ± 10°) or vertical (90° ± 10°) lines\n",
    "            if not ((-20 <= angle <= 10) or (70 <= angle <= 110)):\n",
    "                continue\n",
    "            \n",
    "            # Filter: length threshold (optional)\n",
    "            length = np.hypot(x2 - x1, y2 - y1)\n",
    "            if length < 100:\n",
    "                continue\"\"\"\n",
    "\n",
    "    cv2.imshow(\"Court Line Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40041b75",
   "metadata": {},
   "source": [
    "### Line stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e98dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class LineStabilizer:\n",
    "    \"\"\"\n",
    "    A class to smooth detected lines over several frames.\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size=5):\n",
    "        # A deque is a list-like container with fast appends and pops from either end.\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        \n",
    "    def add_lines(self, lines):\n",
    "        \"\"\"Adds the lines from a new frame to the buffer.\"\"\"\n",
    "        if lines is not None:\n",
    "            self.buffer.append(lines)\n",
    "            \n",
    "    def get_stable_lines(self):\n",
    "        \"\"\"Averages the lines in the buffer to get a stable result.\"\"\"\n",
    "        # Combine all lines from all frames in the buffer into one big list\n",
    "        all_lines = [line for frame_lines in self.buffer for line in frame_lines]\n",
    "        \n",
    "        if not all_lines:\n",
    "            return None\n",
    "            \n",
    "        # --- We use the same merging logic as before, but on a larger, more stable dataset ---\n",
    "        horizontal= []\n",
    "        for line in all_lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "            if -15 < angle < 15:\n",
    "                horizontal.append(line)\n",
    "        \n",
    "        \n",
    "        # === 1. Merge Horizontal Lines ===\n",
    "        if horizontal is not None and len(horizontal) > 0:\n",
    "            # Sort lines by their y-coordinate to process them from top to bottom\n",
    "            horizontal.sort(key=lambda line: line[1])\n",
    "            merged_lines = []\n",
    "            while len(horizontal) > 0:\n",
    "                base_line = horizontal.pop(0)\n",
    "                y_base = (base_line[1] + base_line[3]) / 2\n",
    "                \n",
    "                group = [base_line]\n",
    "                remaining_lines = []\n",
    "                for line in horizontal:\n",
    "                    y_curr = (line[1] + line[3]) / 2\n",
    "                    if abs(y_curr - y_base) < 20:\n",
    "                        group.append(line)\n",
    "                    else:\n",
    "                        remaining_lines.append(line)\n",
    "                horizontal = remaining_lines\n",
    "                \n",
    "                x_coords = np.array([line[0] for line in group] + [line[2] for line in group])\n",
    "                y_coords = np.array([line[1] for line in group] + [line[3] for line in group])\n",
    "                \n",
    "                avg_y = int(np.mean(y_coords))\n",
    "                min_x = int(np.min(x_coords))\n",
    "                max_x = int(np.max(x_coords))\n",
    "                \n",
    "                merged_lines.append([min_x, avg_y, max_x, avg_y])\n",
    "        return merged_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f208a198",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m horizontal, vertical \u001b[38;5;241m=\u001b[39m detect_lines(edges)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m horizontal:\n\u001b[0;32m--> 102\u001b[0m     x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m line[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mline(frame, (x1, y1), (x2, y2), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m vertical:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = \"VideoInput/video_input2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Use your previously found source points\n",
    "src_points = np.float32([[288.0, 152.0], [668.0, 150.0], [182.0, 429.0], [783.0, 428.0]])\n",
    "width, height = 400, 500\n",
    "dst_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Initialize the stabilizer before the loop\n",
    "line_stabilizer = LineStabilizer(buffer_size=15)\n",
    "\n",
    "def filter_pixels(gray):\n",
    "    \"\"\"\n",
    "    Filter pixels by using the court line structure\n",
    "    \"\"\"\n",
    "    dist_tau = 3\n",
    "    intensity_threshold = 40\n",
    "    for i in range(dist_tau, len(gray) - dist_tau):\n",
    "      for j in range(dist_tau, len(gray[0]) - dist_tau):\n",
    "        if gray[i, j] == 0:\n",
    "            continue\n",
    "        if (gray[i, j] - gray[i + dist_tau, j] > intensity_threshold and gray[i, j] - gray[i - dist_tau, j] > intensity_threshold):\n",
    "            continue\n",
    "        if (gray[i, j] - gray[i, j + dist_tau] > intensity_threshold and gray[i, j] - gray[i, j - dist_tau] > intensity_threshold):\n",
    "            continue\n",
    "        gray[i, j] = 0\n",
    "    return gray\n",
    "\n",
    "def classify_lines(lines):\n",
    "    \"\"\"\n",
    "    Classify lines into horizontal and vertical based on their angle.\n",
    "    \"\"\"\n",
    "    horizontal = []\n",
    "    vertical = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        \n",
    "        if -15 < angle < 15:  # Horizontal line\n",
    "            horizontal.append((x1, y1, x2, y2))\n",
    "        elif 45 < angle < 100 or -100 < angle < -45:  # Vertical line\n",
    "            vertical.append((x1, y1, x2, y2))\n",
    "    \n",
    "    return horizontal, vertical\n",
    "\n",
    "def merge_lines(horizontal):\n",
    "    new_horizontal= []\n",
    "    \n",
    "    # === 1. Merge Horizontal Lines ===\n",
    "    if horizontal is not None and len(horizontal) > 0:\n",
    "        # Sort lines by their y-coordinate to process them from top to bottom\n",
    "        horizontal.sort(key=lambda line: line[1])\n",
    "        \n",
    "        while len(horizontal) > 0:\n",
    "            base_line = horizontal.pop(0)\n",
    "            y_base = (base_line[1] + base_line[3]) / 2\n",
    "            \n",
    "            group, horizontal = [base_line], [line for line in horizontal if not (abs(((line[1] + line[3]) / 2) - y_base) < 20)]\n",
    "            all_x = np.array([p for line in group for p in (line[0], line[2])])\n",
    "            all_y = np.array([p for line in group for p in (line[1], line[3])])\n",
    "            new_horizontal.append([int(np.min(all_x)), int(np.mean(all_y)), int(np.max(all_x)), int(np.mean(all_y))])\n",
    "    return new_horizontal\n",
    "\n",
    "def detect_lines(frame):\n",
    "    # Detect all lines\n",
    "    lines = cv2.HoughLinesP(gray, 1, np.pi / 180, 80, minLineLength=50, maxLineGap=20)\n",
    "    lines = np.squeeze(lines)\n",
    "    \n",
    "    horizontal, vertical = classify_lines(lines)\n",
    "    \n",
    "    # 2. Add raw lines to our stabilizer\n",
    "    line_stabilizer.add_lines(horizontal)\n",
    "    \n",
    "    # 3. Get the STABLE lines by averaging over the buffer\n",
    "    horizontal = line_stabilizer.get_stable_lines()\n",
    "    #horizontal = merge_lines(horizontal)\n",
    "    \n",
    "    return horizontal, vertical\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (960, 540))\n",
    "    \n",
    "    # 1. Get binary image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    edges = cv2.Canny(gray, 75, 150)\n",
    "    \n",
    "    horizontal, vertical = detect_lines(edges)\n",
    "    \n",
    "    for line in horizontal:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    \n",
    "    for line in vertical:\n",
    "        x1, y1, x2, y2 = line\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "    \n",
    "    #warped_frame = cv2.warpPerspective(frame, M, (width, height))\n",
    "    cv2.imshow(\"Court Line Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ec5d4",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Calibration:\n",
    "    \"\"\"\n",
    "    A class to handle the interactive calibration process where a user\n",
    "    draws a rectangle to define a Region of Interest (ROI).\n",
    "    \"\"\"\n",
    "    def __init__(self, frame):\n",
    "        \"\"\"\n",
    "        Initializes the Calibration object.\n",
    "        Args:\n",
    "            frame (np.array): The first frame of the video for the user to draw on.\n",
    "        \"\"\"\n",
    "        self.frame = frame.copy()\n",
    "        self.roi_points = []\n",
    "        self.drawing = False\n",
    "        self.roi_rect = None\n",
    "        self.bottom_service_line = None\n",
    "\n",
    "    def _mouse_handler(self, event, x, y, flags, param):\n",
    "        \"\"\"\n",
    "        Internal mouse handler for drawing the rectangle.\n",
    "        \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drawing = True\n",
    "            self.roi_points = [(x, y)]\n",
    "\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and self.drawing:\n",
    "            frame_copy = self.frame.copy()\n",
    "            cv2.rectangle(frame_copy, self.roi_points[0], (x, y), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Calibration\", frame_copy)\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.drawing = False\n",
    "            self.roi_points.append((x, y))\n",
    "            frame_copy = self.frame.copy()\n",
    "            cv2.rectangle(frame_copy, self.roi_points[0], self.roi_points[1], (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Calibration\", frame_copy)\n",
    "\n",
    "    def _merge_lines(self, lines):\n",
    "        \"\"\"\n",
    "        Merges a list of horizontal line segments into a single line.\n",
    "        \"\"\"\n",
    "        if not lines:\n",
    "            return None\n",
    "        \n",
    "        # Flatten the list of lines to get all x and y coordinates\n",
    "        all_x = [p[0] for p in lines] + [p[2] for p in lines]\n",
    "        all_y = [p[1] for p in lines] + [p[3] for p in lines]\n",
    "        \n",
    "        # Calculate the start and end points of the merged line\n",
    "        min_x = min(all_x)\n",
    "        max_x = max(all_x)\n",
    "        avg_y = int(np.mean(all_y))\n",
    "        \n",
    "        return ((min_x, avg_y), (max_x, avg_y))\n",
    "\n",
    "    def get_roi(self):\n",
    "        \"\"\"\n",
    "        Starts the calibration UI, waits for user input, and returns the ROI.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (x1, y1, x2, y2) representing the ROI rectangle,\n",
    "                   or None if calibration is cancelled.\n",
    "        \"\"\"\n",
    "        print(\"--- Court Calibration ---\")\n",
    "        print(\"Click and drag to draw a box around the bottom service line.\")\n",
    "        print(\"After drawing the box, press 'c' to start processing.\")\n",
    "        \n",
    "        cv2.imshow(\"Calibration\", self.frame)\n",
    "        cv2.setMouseCallback(\"Calibration\", self._mouse_handler)\n",
    "        \n",
    "        key = cv2.waitKey(0)\n",
    "        \n",
    "        cv2.destroyWindow(\"Calibration\")\n",
    "\n",
    "        if key == ord('c') and len(self.roi_points) == 2:\n",
    "            # Ensure x1 < x2 and y1 < y2\n",
    "            x1 = min(self.roi_points[0][0], self.roi_points[1][0])\n",
    "            y1 = min(self.roi_points[0][1], self.roi_points[1][1])\n",
    "            x2 = max(self.roi_points[0][0], self.roi_points[1][0])\n",
    "            y2 = max(self.roi_points[0][1], self.roi_points[1][1])\n",
    "            self.roi_rect = (x1, y1, x2, y2)\n",
    "            print(\"Calibration successful.\")\n",
    "            return self.roi_rect\n",
    "        else:\n",
    "            print(\"Calibration cancelled or incomplete.\")\n",
    "            return None\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Gets the ROI and then performs line detection within it, displaying the result.\n",
    "        \"\"\"\n",
    "        roi_rect = self.get_roi()\n",
    "        if roi_rect is None:\n",
    "            return\n",
    "\n",
    "        x1, y1, x2, y2 = roi_rect\n",
    "        roi = self.frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # --- Improved image processing pipeline ---\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply a Gaussian blur to reduce noise and improve Canny performance\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        # Apply Canny edge detection directly on the grayscale (blurred) image\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        \n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=30, minLineLength=20, maxLineGap=15)\n",
    "        \n",
    "        horizontal_lines = []\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                lx1, ly1, lx2, ly2 = line[0]\n",
    "                # Filter for lines that are nearly horizontal\n",
    "                angle = np.degrees(np.arctan2(ly2 - ly1, lx2 - lx1))\n",
    "                if abs(angle) < 15:\n",
    "                    horizontal_lines.append((lx1, ly1, lx2, ly2))\n",
    "        \n",
    "        # Merge the detected horizontal lines into one\n",
    "        merged_line = self._merge_lines(horizontal_lines)\n",
    "        self.bottom_service_line = merged_line\n",
    "        \n",
    "        # Draw the final, clean line on the ROI\n",
    "        if merged_line:\n",
    "            p1, p2 = merged_line\n",
    "            cv2.line(roi, p1, p2, (0, 255, 0), 1)\n",
    "        \n",
    "        cv2.imshow(\"ROI with Detected Lines\", roi)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    video_path = \"VideoInput/video_input2.mp4\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read the first frame.\")\n",
    "        exit()\n",
    "    first_frame = cv2.resize(first_frame, (960, 540))\n",
    "\n",
    "    c = Calibration(first_frame)\n",
    "    c.run()\n",
    "    \n",
    "    cap.release()\n",
    "    print(c.bottom_service_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072f504",
   "metadata": {},
   "source": [
    "### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "156cdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class LineStabilizer2:\n",
    "    \"\"\"\n",
    "    A class to smooth detected lines over several frames.\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size=5):\n",
    "        # A deque is a list-like container with fast appends and pops from either end.\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        \n",
    "    def add_lines(self, lines):\n",
    "        \"\"\"Adds the lines from a new frame to the buffer.\"\"\"\n",
    "        if lines is not None:\n",
    "            self.buffer.append(lines)\n",
    "            \n",
    "    def get_stable_lines(self):\n",
    "        \"\"\"Averages the lines in the buffer to get a stable result.\"\"\"\n",
    "        # Combine all lines from all frames in the buffer into one big list\n",
    "        all_lines = [line for frame_lines in self.buffer for line in frame_lines]\n",
    "        \n",
    "        if not all_lines:\n",
    "            return None\n",
    "            \n",
    "        # --- We use the same merging logic as before, but on a larger, more stable dataset ---\n",
    "        horizontal= []\n",
    "        for line in all_lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "            if -15 < angle < 15:\n",
    "                horizontal.append(line)\n",
    "        \n",
    "        \n",
    "        # === 1. Merge Horizontal Lines ===\n",
    "        if horizontal is not None and len(horizontal) > 0:\n",
    "            # Sort lines by their y-coordinate to process them from top to bottom\n",
    "            horizontal.sort(key=lambda line: line[1])\n",
    "            merged_lines = []\n",
    "            while len(horizontal) > 0:\n",
    "                base_line = horizontal.pop(0)\n",
    "                y_base = (base_line[1] + base_line[3]) / 2\n",
    "                x1_base = base_line[0]\n",
    "                x2_base = base_line[2]\n",
    "                \n",
    "                group = [base_line]\n",
    "                remaining_lines = []\n",
    "                for line in horizontal:\n",
    "                    y_curr = (line[1] + line[3]) / 2\n",
    "                    if abs(y_curr - y_base) < 10 and (line[0] < x2_base + 20 and line[2] > x1_base - 20):\n",
    "                        group.append(line)\n",
    "                    else:\n",
    "                        remaining_lines.append(line)\n",
    "                horizontal = remaining_lines\n",
    "                \n",
    "                x_coords = np.array([line[0] for line in group] + [line[2] for line in group])\n",
    "                y_coords = np.array([line[1] for line in group] + [line[3] for line in group])\n",
    "                \n",
    "                avg_y = int(np.mean(y_coords))\n",
    "                min_x = int(np.min(x_coords))\n",
    "                max_x = int(np.max(x_coords))\n",
    "                \n",
    "                merged_lines.append([min_x, avg_y, max_x, avg_y])\n",
    "        return merged_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4afeeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Court():\n",
    "    def __init__(self):\n",
    "        self.service_line_angle = 0\n",
    "        self.lines = {\n",
    "            'top_baseline': None,\n",
    "            'bottom_baseline': None, \n",
    "            'top_service_line': None,\n",
    "            'bottom_service_line': None,\n",
    "            'left_singles_line': None, \n",
    "            'right_singles_line': None,\n",
    "            'left_doubles_line': None,\n",
    "            'right_doubles_line': None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bff78a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_lines(lines):\n",
    "    \"\"\"\n",
    "    Classify lines into horizontal and vertical based on their angle.\n",
    "    \"\"\"\n",
    "    horizontal = []\n",
    "    vertical = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        \n",
    "        if -15 < angle < 15:  # Horizontal line\n",
    "            horizontal.append((x1, y1, x2, y2))\n",
    "        elif 45 < angle < 100 or -100 < angle < -45:  # Vertical line\n",
    "            vertical.append((x1, y1, x2, y2))\n",
    "    \n",
    "    return horizontal, vertical\n",
    "\n",
    "def merge_lines(horizontal):\n",
    "    new_horizontal= []\n",
    "    \n",
    "    if horizontal is not None and len(horizontal) > 0:\n",
    "        horizontal.sort(key=lambda line: line[1])\n",
    "        \n",
    "        while len(horizontal) > 0:\n",
    "            base_line = horizontal.pop(0)\n",
    "            y_base = (base_line[1] + base_line[3]) / 2\n",
    "            \n",
    "            group, horizontal = [base_line], [line for line in horizontal if not (abs(((line[1] + line[3]) / 2) - y_base) < 5)]\n",
    "            all_x = np.array([p for line in group for p in (line[0], line[2])])\n",
    "            all_y = np.array([p for line in group for p in (line[1], line[3])])\n",
    "            new_horizontal.append([int(np.min(all_x)), int(np.mean(all_y)), int(np.max(all_x)), int(np.mean(all_y))])\n",
    "    return new_horizontal\n",
    "\n",
    "def detect_lines(gray):\n",
    "    # Detect all lines\n",
    "    lines = cv2.HoughLinesP(gray, 1, np.pi / 180, 80, minLineLength=90, maxLineGap=20)\n",
    "    lines = np.squeeze(lines)\n",
    "    \n",
    "    unstable_horizontal, stable_vertical = classify_lines(lines)\n",
    "    \n",
    "    line_stabilizer.add_lines(unstable_horizontal)\n",
    "    stable_horizontal = line_stabilizer.get_stable_lines()\n",
    "    \n",
    "    #horizontal = merge_lines(horizontal)\n",
    "    \n",
    "    return stable_horizontal, stable_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93cfab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = \"VideoInput/video_input2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Use your previously found source points\n",
    "src_points = np.float32([[288.0, 152.0], [668.0, 150.0], [182.0, 429.0], [783.0, 428.0]])\n",
    "width, height = 400, 500\n",
    "dst_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Initialize the stabilizer before the loop\n",
    "line_stabilizer = LineStabilizer2(buffer_size=15)\n",
    "court = Court()\n",
    "                \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (960, 540))\n",
    "    \n",
    "    # 1. Get binary image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #gray = cv2.threshold(frame, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    horizontal, vertical = detect_lines(edges)\n",
    "    \n",
    "    \n",
    "    for line in horizontal:\n",
    "        x1, y1, x2, y2 = line\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    \n",
    "    for line in vertical:\n",
    "        x1, y1, x2, y2 = line\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "        \n",
    "    #warped_frame = cv2.warpPerspective(frame, M, (width, height))\n",
    "    cv2.imshow(\"Court Line Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547eec55",
   "metadata": {},
   "source": [
    "### homograft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83ae67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CourtReference:\n",
    "    \"\"\"\n",
    "    Court reference model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.baseline_top = ((286, 561), (1379, 561))\n",
    "        self.baseline_bottom = ((286, 2935), (1379, 2935))\n",
    "        self.net = ((286, 1748), (1379, 1748))\n",
    "        self.left_court_line = ((286, 561), (286, 2935))\n",
    "        self.right_court_line = ((1379, 561), (1379, 2935))\n",
    "        self.left_inner_line = ((423, 561), (423, 2935))\n",
    "        self.right_inner_line = ((1242, 561), (1242, 2935))\n",
    "        self.middle_line = ((832, 1110), (832, 2386))\n",
    "        self.top_inner_line = ((423, 1110), (1242, 1110))\n",
    "        self.bottom_inner_line = ((423, 2386), (1242, 2386))\n",
    "        self.top_extra_part = (832.5, 580)\n",
    "        self.bottom_extra_part = (832.5, 2910)\n",
    "\n",
    "        self.court_conf = {1: [*self.baseline_top, *self.baseline_bottom],\n",
    "                           2: [self.left_inner_line[0], self.right_inner_line[0], self.left_inner_line[1],\n",
    "                               self.right_inner_line[1]],\n",
    "                           3: [self.left_inner_line[0], self.right_court_line[0], self.left_inner_line[1],\n",
    "                               self.right_court_line[1]],\n",
    "                           4: [self.left_court_line[0], self.right_inner_line[0], self.left_court_line[1],\n",
    "                               self.right_inner_line[1]],\n",
    "                           5: [*self.top_inner_line, *self.bottom_inner_line],\n",
    "                           6: [*self.top_inner_line, self.left_inner_line[1], self.right_inner_line[1]],\n",
    "                           7: [self.left_inner_line[0], self.right_inner_line[0], *self.bottom_inner_line],\n",
    "                           8: [self.right_inner_line[0], self.right_court_line[0], self.right_inner_line[1],\n",
    "                               self.right_court_line[1]],\n",
    "                           9: [self.left_court_line[0], self.left_inner_line[0], self.left_court_line[1],\n",
    "                               self.left_inner_line[1]],\n",
    "                           10: [self.top_inner_line[0], self.middle_line[0], self.bottom_inner_line[0],\n",
    "                                self.middle_line[1]],\n",
    "                           11: [self.middle_line[0], self.top_inner_line[1], self.middle_line[1],\n",
    "                                self.bottom_inner_line[1]],\n",
    "                           12: [*self.bottom_inner_line, self.left_inner_line[1], self.right_inner_line[1]]}\n",
    "        self.line_width = 1\n",
    "        self.court_width = 1117\n",
    "        self.court_height = 2408\n",
    "        self.top_bottom_border = 549\n",
    "        self.right_left_border = 274\n",
    "        self.court_total_width = self.court_width + self.right_left_border * 2\n",
    "        self.court_total_height = self.court_height + self.top_bottom_border * 2\n",
    "\n",
    "        self.court = cv2.cvtColor(cv2.imread('old/court_configurations/court_reference.png'), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def build_court_reference(self):\n",
    "        \"\"\"\n",
    "        Create court reference image using the lines positions\n",
    "        \"\"\"\n",
    "        court = np.zeros((self.court_height + 2 * self.top_bottom_border, self.court_width + 2 * self.right_left_border), dtype=np.uint8)\n",
    "        cv2.line(court, *self.baseline_top, 1, self.line_width)\n",
    "        cv2.line(court, *self.baseline_bottom, 1, self.line_width)\n",
    "        # cv2.line(court, *self.net, 1, self.line_width)\n",
    "        cv2.line(court, *self.top_inner_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.bottom_inner_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.left_court_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.right_court_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.left_inner_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.right_inner_line, 1, self.line_width)\n",
    "        cv2.line(court, *self.middle_line, 1, self.line_width)\n",
    "        court = cv2.dilate(court, np.ones((5, 5), dtype=np.uint8))\n",
    "        plt.imsave('old/court_configurations/court_reference.png', court, cmap='gray')\n",
    "        self.court = court\n",
    "        return court\n",
    "\n",
    "    def get_important_lines(self):\n",
    "        \"\"\"\n",
    "        Returns all lines of the court\n",
    "        \"\"\"\n",
    "        lines = [*self.baseline_top, *self.baseline_bottom, *self.net, *self.left_court_line, *self.right_court_line,\n",
    "                 *self.left_inner_line, *self.right_inner_line, *self.middle_line,\n",
    "                 *self.top_inner_line, *self.bottom_inner_line]\n",
    "        return lines\n",
    "\n",
    "    def get_extra_parts(self):\n",
    "        parts = [self.top_extra_part, self.bottom_extra_part]\n",
    "        return parts\n",
    "\n",
    "    def save_all_court_configurations(self):\n",
    "        \"\"\"\n",
    "        Create all configurations of 4 points on court reference\n",
    "        \"\"\"\n",
    "        for i, conf in self.court_conf.items():\n",
    "            c = cv2.cvtColor(255 - self.court, cv2.COLOR_GRAY2BGR)\n",
    "            for p in conf:\n",
    "                c = cv2.circle(c, p, 15, (0, 0, 255), 30)\n",
    "            cv2.imwrite(f'old/court_configurations/court_conf_{i}.png', c)\n",
    "\n",
    "    def get_court_mask(self, mask_type=0):\n",
    "        \"\"\"\n",
    "        Get mask of the court\n",
    "        \"\"\"\n",
    "        mask = np.ones_like(self.court)\n",
    "        if mask_type == 1:  # Bottom half court\n",
    "            mask[:self.net[0][1] - 1000, :] = 0\n",
    "        elif mask_type == 2:  # Top half court\n",
    "            mask[self.net[0][1]:, :] = 0\n",
    "        elif mask_type == 3: # court without margins\n",
    "            mask[:self.baseline_top[0][1], :] = 0\n",
    "            mask[self.baseline_bottom[0][1]:, :] = 0\n",
    "            mask[:, :self.left_court_line[0][0]] = 0\n",
    "            mask[:, self.right_court_line[0][0]:] = 0\n",
    "        return mask\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    c = CourtReference()\n",
    "    c.build_court_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58c00996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confi_score(matrix, court_reference, frame, gray):\n",
    "    \"\"\"\n",
    "    Calculate transformation score\n",
    "    \"\"\"\n",
    "    court = cv2.warpPerspective(court_reference.court, matrix, frame.shape[1::-1])\n",
    "    court[court > 0] = 1\n",
    "    gray = gray.copy()\n",
    "    gray[gray > 0] = 1\n",
    "    correct = court * gray\n",
    "    wrong = court - correct\n",
    "    c_p = np.sum(correct)\n",
    "    w_p = np.sum(wrong)\n",
    "    return c_p - 0.5 * w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d007b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_conf = 0\n",
    "court_reference = CourtReference()\n",
    "from sympy import Line\n",
    "from itertools import combinations\n",
    "def line_intersection(line1, line2):\n",
    "    \"\"\"\n",
    "    Find 2 lines intersection point\n",
    "    \"\"\"\n",
    "    l1 = Line(line1[0], line1[1])\n",
    "    l2 = Line(line2[0], line2[1])\n",
    "\n",
    "    intersection = l1.intersection(l2)\n",
    "    return intersection[0].coordinates\n",
    "\n",
    "def sort_intersection_points(intersections):\n",
    "    \"\"\"\n",
    "    sort intersection points from top left to bottom right\n",
    "    \"\"\"\n",
    "    y_sorted = sorted(intersections, key=lambda x: x[1])\n",
    "    p12 = y_sorted[:2]\n",
    "    p34 = y_sorted[2:]\n",
    "    p12 = sorted(p12, key=lambda x: x[0])\n",
    "    p34 = sorted(p34, key=lambda x: x[0])\n",
    "    return p12 + p34\n",
    "\n",
    "def find_homography(horizontal_lines, vertical_lines, court_reference, frame, gray):\n",
    "        \"\"\"\n",
    "        Finds transformation from reference court to frame`s court using 4 pairs of matching points\n",
    "        \"\"\"\n",
    "        max_score = -np.inf\n",
    "        max_mat = None\n",
    "        max_inv_mat = None\n",
    "        k = 0\n",
    "        # Loop over every pair of horizontal lines and every pair of vertical lines\n",
    "        for horizontal_pair in list(combinations(horizontal_lines, 2)):\n",
    "            for vertical_pair in list(combinations(vertical_lines, 2)):\n",
    "                h1, h2 = horizontal_pair\n",
    "                v1, v2 = vertical_pair\n",
    "                # Finding intersection points of all lines\n",
    "                i1 = line_intersection((tuple(h1[:2]), tuple(h1[2:])), (tuple(v1[0:2]), tuple(v1[2:])))\n",
    "                i2 = line_intersection((tuple(h1[:2]), tuple(h1[2:])), (tuple(v2[0:2]), tuple(v2[2:])))\n",
    "                i3 = line_intersection((tuple(h2[:2]), tuple(h2[2:])), (tuple(v1[0:2]), tuple(v1[2:])))\n",
    "                i4 = line_intersection((tuple(h2[:2]), tuple(h2[2:])), (tuple(v2[0:2]), tuple(v2[2:])))\n",
    "\n",
    "                intersections = [i1, i2, i3, i4]\n",
    "                intersections = sort_intersection_points(intersections)\n",
    "\n",
    "                for i, configuration in court_reference.court_conf.items():\n",
    "                    # Find transformation\n",
    "                    matrix, _ = cv2.findHomography(np.float32(configuration), np.float32(intersections), method=0)\n",
    "                    inv_matrix = cv2.invert(matrix)[1]\n",
    "                    # Get transformation score\n",
    "                    confi_score = get_confi_score(matrix, court_reference, frame, gray)\n",
    "\n",
    "                    if max_score < confi_score:\n",
    "                        max_score = confi_score\n",
    "                        max_mat = matrix\n",
    "                        max_inv_mat = inv_matrix\n",
    "                        best_conf = i\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "        return max_mat, max_inv_mat, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = \"VideoInput/video_input2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Use your previously found source points\n",
    "src_points = np.float32([[288.0, 152.0], [668.0, 150.0], [182.0, 429.0], [783.0, 428.0]])\n",
    "width, height = 400, 500\n",
    "dst_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Initialize the stabilizer before the loop\n",
    "line_stabilizer = LineStabilizer2(buffer_size=15)\n",
    "court = Court()\n",
    "                \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (960, 540))\n",
    "    \n",
    "    # 1. Get binary image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    horizontal, vertical = detect_lines(edges)\n",
    "    \n",
    "    court_warp_matrix, game_warp_matrix, court_score = find_homography(horizontal, vertical, court_reference, frame, gray)\n",
    "    print(court_warp_matrix, game_warp_matrix, court_score)\n",
    "    for line in horizontal:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    \n",
    "    for line in vertical:\n",
    "        x1, y1, x2, y2 = line\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "        \n",
    "    #warped_frame = cv2.warpPerspective(frame, M, (width, height))\n",
    "    cv2.imshow(\"Court Line Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
